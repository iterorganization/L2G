#!/usr/bin/env bash

declare -a flatopts
flatopts=()

while [[ $# -gt 0 ]]; do
    key="$1"
    case $key in
        -h|--help)
            echo "This script submits a L2G case to the ITER HPC."
            echo "Example:"
            echo "submitL2G l2g_case.json"
            echo "Available options (verbatim):"
            echo "partition=<partition_name> - Specify slurm partition name. No spaces between = operator"
            echo "cpus_per_task=<num_of_cpus> - Specify how many OpenMP threads you wish to use. No spaces between = operator.Default, maximum available"
            exit
            ;;
        partition=*)
            PARTITION_NAME=${1#*=}
            shift
            ;;
        cpus_per_task=*)
            CPUS_PER_TASK=${1#*=}
            shift
            ;;
        *.yaml) # L2G case file
            CONF_FILE=$1
            shift
            ;;
        *) # Pass them to flat
            flatopts+=("$key")
            shift
            ;;
    esac
done

SCRIPTPATH="$( cd -- "$(dirname "$0")" >/dev/null 2>&1 ; pwd -P )"

#JOB_NAME=$(echo ${CONF_FILE} | python3 -c "import sys,l2g.workflow; print(l2g.workflow.json_loads(open(sys.stdin.read().strip(), 'r').read())['name'])")
JOB_NAME="${flatopts[1]}-${flatopts[2]}" # The second command relates to the geometry
JOB_NAME=${JOB_NAME:-"L2G-job"}
echo "Running job ${JOB_NAME}"
LOG_DIR=$(realpath ${CONF_FILE} | xargs dirname)/log
mkdir -p ${LOG_DIR}


LOG_NAME=${LOG_DIR}/${JOB_NAME}

# Add time stamp if date command exists
if hash date 2>/dev/null; then
    LOG_NAME="${LOG_NAME}_$(date +%d-%m-%y_%T)"
fi

LOG_NAME="${LOG_NAME}_slurm.log"
# Defaults to gen10_ib
PARTITION_NAME=${PARTITION_NAME:-"gen10_ib"}

# Just to be sure, when generating graphics on compute nodes, use Agg for
# matplotlib backend. Otherwise an error "could not connect to display"
# will crash the run
export MPLBACKEND=Agg

CPUS_PER_TASK=${CPUS_PER_TASK:-$(sinfo -p ${PARTITION_NAME} -O "cpus" --noheader)}
sbatch --job-name=${JOB_NAME} --output=${LOG_NAME} --partition=${PARTITION_NAME} --cpus-per-task=${CPUS_PER_TASK} --nodes=1 ${SCRIPTPATH}/FLAT.sbatch "${CONF_FILE}" "${flatopts[@]}"